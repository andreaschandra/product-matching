{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(1, '../src/')\n",
    "\n",
    "from image_tools import *\n",
    "from text_tools import *\n",
    "from data_prepare import *\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.layers import Embedding, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../ndsc_data/\"\n",
    "path_image = '../../ndsc_data/training_img/training_img/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = pd.read_csv(os.path.join(data_path, \"new_training_set.csv\"),\n",
    "                      usecols=[\"title_1\", \"image_1\", \"title_2\", \"image_2\", \"Label\"])\n",
    "d_test = pd.read_csv(os.path.join(data_path, \"new_test_sample.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10181, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_1</th>\n",
       "      <th>image_1</th>\n",
       "      <th>title_2</th>\n",
       "      <th>image_2</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Johnson’s ® Top to Toe Hair &amp; Body Bath 500ml</td>\n",
       "      <td>fdff8b9b8229da091dd7d070aae05f81.jpg</td>\n",
       "      <td>Johnson's cottontouch top to toe hair &amp; body b...</td>\n",
       "      <td>41e191742760932598c7bd201e5dad47.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sandal Humble</td>\n",
       "      <td>906cc44f0be72d4e767669b5b63e3a17.jpg</td>\n",
       "      <td>Sandal Humble Glass - Glanzton</td>\n",
       "      <td>7a556b836bfdd08ea592216440524a34.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PROMO LIKUID LIKUIT LIQUIT BABY POD LIQUID SAL...</td>\n",
       "      <td>475c26635de18b9f93032400732ff336.jpg</td>\n",
       "      <td>Voporizer Liquit - Likuit - Likuid - Liquid Pr...</td>\n",
       "      <td>ace93bec689f3f1565800c500a8341fa.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6 Pasang / Set Anting Tusuk Bentuk Lingkaran A...</td>\n",
       "      <td>e630997f6217555d6026547ad1c15f0b.jpg</td>\n",
       "      <td>Subei 6 Pasang / Set Anting Tusuk Boho Bohemia...</td>\n",
       "      <td>31abbc176b09f5bd1728cfc3ecbbfb9c.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROREC NATURAL SKIN CARE MASK ROREC SHEET MASK ...</td>\n",
       "      <td>a27d11700a7902febd039dc3a96f10f2.jpg</td>\n",
       "      <td>Rorec 86 Natural Skin Care Shert Mask All Variant</td>\n",
       "      <td>813ad9dd638c10f1765db9dde20c9e42.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title_1  \\\n",
       "0      Johnson’s ® Top to Toe Hair & Body Bath 500ml   \n",
       "1                                      Sandal Humble   \n",
       "2  PROMO LIKUID LIKUIT LIQUIT BABY POD LIQUID SAL...   \n",
       "3  6 Pasang / Set Anting Tusuk Bentuk Lingkaran A...   \n",
       "4  ROREC NATURAL SKIN CARE MASK ROREC SHEET MASK ...   \n",
       "\n",
       "                                image_1  \\\n",
       "0  fdff8b9b8229da091dd7d070aae05f81.jpg   \n",
       "1  906cc44f0be72d4e767669b5b63e3a17.jpg   \n",
       "2  475c26635de18b9f93032400732ff336.jpg   \n",
       "3  e630997f6217555d6026547ad1c15f0b.jpg   \n",
       "4  a27d11700a7902febd039dc3a96f10f2.jpg   \n",
       "\n",
       "                                             title_2  \\\n",
       "0  Johnson's cottontouch top to toe hair & body b...   \n",
       "1                     Sandal Humble Glass - Glanzton   \n",
       "2  Voporizer Liquit - Likuit - Likuid - Liquid Pr...   \n",
       "3  Subei 6 Pasang / Set Anting Tusuk Boho Bohemia...   \n",
       "4  Rorec 86 Natural Skin Care Shert Mask All Variant   \n",
       "\n",
       "                                image_2  Label  \n",
       "0  41e191742760932598c7bd201e5dad47.jpg      0  \n",
       "1  7a556b836bfdd08ea592216440524a34.jpg      0  \n",
       "2  ace93bec689f3f1565800c500a8341fa.jpg      0  \n",
       "3  31abbc176b09f5bd1728cfc3ecbbfb9c.jpg      0  \n",
       "4  813ad9dd638c10f1765db9dde20c9e42.jpg      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train2 = d_train.sample(300)\n",
    "d_test2 = d_test.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train2.title_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train2.title_1 = d_train2.title_1.fillna('')\n",
    "d_train2.title_2 = d_train2.title_2.fillna('')\n",
    "\n",
    "d_train2['title_1_pre'] = d_train2.title_1.apply(text_cleansing)\n",
    "d_train2['title_2_pre'] = d_train2.title_2.apply(text_cleansing)\n",
    "\n",
    "d_test2['title_1_pre'] = d_test2.title_1.apply(text_cleansing)\n",
    "d_test2['title_2_pre'] = d_test2.title_2.apply(text_cleansing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train, d_test, word2idx, idx2word = data_text_prep(d_train2, d_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(word2idx)\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = ShopeeDataset(d_train, d_test, word2idx, idx2word)\n",
    "dataset_val = ShopeeDataset(d_train, d_test, word2idx, idx2word, stage = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = dataset_train.dataset['train'][1]\n",
    "t1_enc_tr, t2_enc_tr, i1_tr, i2_tr, label_tr = [],[],[],[],[]\n",
    "for i in range(len_train):\n",
    "    t1_encode, t2_encode, i1_scaled, i2_scaled, label0 = dataset_train.__getitem__(i)\n",
    "    t1_enc_tr.append(t1_encode)\n",
    "    t2_enc_tr.append(t2_encode)\n",
    "    i1_tr.append(i1_scaled)\n",
    "    i2_tr.append(i2_scaled)\n",
    "    label_tr.append(label0)\n",
    "    \n",
    "t1_enc_tr = np.stack(t1_enc_tr)\n",
    "t2_enc_tr = np.stack(t2_enc_tr)\n",
    "i1_tr = np.stack(i1_tr)/255\n",
    "i2_tr = np.stack(i2_tr)/255\n",
    "label_tr = np.array(label_tr)\n",
    "\n",
    "\n",
    "len_val = dataset_train.dataset['val'][1]\n",
    "t1_enc_val, t2_enc_val, i1_val, i2_val, label_val = [],[],[],[],[]\n",
    "for i in range(len_val):\n",
    "    t1_encode, t2_encode, i1_scaled, i2_scaled, label0 = dataset_val.__getitem__(i)\n",
    "    t1_enc_val.append(t1_encode)\n",
    "    t2_enc_val.append(t2_encode)\n",
    "    i1_val.append(i1_scaled)\n",
    "    i2_val.append(i2_scaled)\n",
    "    label_val.append(label0)\n",
    "    \n",
    "t1_enc_val = np.stack(t1_enc_val)\n",
    "t2_enc_val = np.stack(t2_enc_val)\n",
    "i1_val = np.stack(i1_val)/255\n",
    "i2_val = np.stack(i2_val)/255    \n",
    "label_val = np.array(label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 224, 224, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in i1_tr:\n",
    "#     if k.shape != (224, 224, 3):\n",
    "#         print(k.shape)\n",
    "#         X= k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tr = label_tr.astype(float)\n",
    "label_val = label_val.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 0.5\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vect):\n",
    "    x, y = vect\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_net() :\n",
    "    IMG_DIM = 224\n",
    "    # input_img = keras.Input(shape=(IMG_DIM,IMG_DIM, 3))\n",
    "    mod1 = Sequential()\n",
    "    mod1.add(MobileNetV2(include_top=False,input_shape=(IMG_DIM,IMG_DIM,3)))\n",
    "    mod1.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "    mod1.add(layers.Reshape((25,256,1)))\n",
    "    return mod1\n",
    "\n",
    "def image_net() :\n",
    "    IMG_DIM = 224\n",
    "    # input_img = keras.Input(shape=(IMG_DIM,IMG_DIM, 3))\n",
    "    mod1 = Sequential()\n",
    "    mod1.add(MobileNetV2(include_top=False,input_shape=(IMG_DIM,IMG_DIM,3)))\n",
    "    mod1.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "    mod1.add(layers.Reshape((25,256,1)))\n",
    "    return mod1\n",
    "\n",
    "def text_net() :\n",
    "    # sentence_indices = keras.Input(25, dtype = 'int32')\n",
    "    mod1 = Sequential()\n",
    "    mod1.add(Embedding(VOCAB_SIZE, 512))\n",
    "    mod1.add(LSTM(256,return_sequences = True))\n",
    "    mod1.add(layers.Reshape((25,256,1)))\n",
    "    return mod1\n",
    "\n",
    "def connect_net() :\n",
    "    ##concate_input = keras.Input(shape=(25,512,1))\n",
    "    mod1 = Sequential()\n",
    "    mod1.add(layers.Conv2D(1, (3, 11), activation='relu'))\n",
    "    mod1.add(layers.MaxPool2D((2, 2)))\n",
    "    mod1.add(layers.Conv2D(1, (3, 11), activation='relu'))\n",
    "    mod1.add(layers.MaxPool2D((2, 2)))\n",
    "    mod1.add(layers.Conv2D(1, (3, 11), activation='relu'))\n",
    "    mod1.add(layers.MaxPool2D((2, 2)))\n",
    "    mod1.add(layers.Reshape((55,)))\n",
    "    return mod1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim_img = (224,224,3)\n",
    "input_dim_txt = (25)\n",
    "eucl_dist_output_shape = 1\n",
    "\n",
    "im_net = image_net()\n",
    "tx_net = text_net()\n",
    "cn_net = connect_net()\n",
    "\n",
    "img_a = keras.Input(shape=input_dim_img)\n",
    "img_b = keras.Input(shape=input_dim_img)\n",
    "\n",
    "txt_a = keras.Input(shape=input_dim_txt)\n",
    "txt_b = keras.Input(shape=input_dim_txt)\n",
    "\n",
    "feat_img_a = im_net(img_a)\n",
    "feat_img_b = im_net(img_b)\n",
    "\n",
    "feat_txt_a = tx_net(txt_a)\n",
    "feat_txt_b = tx_net(txt_b)\n",
    "\n",
    "concat_A = layers.Concatenate(axis=2)([feat_img_a, feat_txt_a])\n",
    "concat_B = layers.Concatenate(axis=2)([feat_img_b, feat_txt_b])\n",
    "\n",
    "vec_a = cn_net(concat_A)\n",
    "vec_b = cn_net(concat_B)\n",
    "\n",
    "simmilarity_dist = layers.Lambda(euclidean_distance, output_shape = eucl_dist_output_shape)([vec_a ,vec_b])\n",
    "\n",
    "prediction = layers.Dense(1,activation='softmax')(simmilarity_dist)\n",
    "model_shopi = keras.Model(inputs = [txt_a, txt_b, img_a, img_b], outputs = prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 25, 256, 1)   5207360     input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 25, 256, 1)   1649152     input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 25, 512, 1)   0           sequential[0][0]                 \n",
      "                                                                 sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 25, 512, 1)   0           sequential[1][0]                 \n",
      "                                                                 sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 55)           102         concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           sequential_2[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2           lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 6,856,616\n",
      "Trainable params: 6,822,504\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_shopi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../ndsc_model/model_shopi/model_{epoch:02d}_{val_loss:.4f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "# opt = keras.optimizers.RMSprop(learning_rate=0.0005)\n",
    "model_shopi.compile(optimizer=opt, loss=contrastive_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6044 - accuracy: 0.6044\n",
      "Epoch 00001: val_loss improved from inf to 0.50667, saving model to ../../ndsc_model/model_shopi/model_01_0.5067.hdf5\n",
      "15/15 [==============================] - 58s 4s/step - loss: 0.6044 - accuracy: 0.6044 - val_loss: 0.5067 - val_accuracy: 0.5067\n",
      "Epoch 2/50\n",
      " 2/15 [===>..........................] - ETA: 23s - loss: 0.7667 - accuracy: 0.7667"
     ]
    }
   ],
   "source": [
    "enc_train = model_shopi.fit([t1_enc_tr, t2_enc_tr, i1_tr, i2_tr],label_tr,\n",
    "                epochs=50,\n",
    "                batch_size=15,\n",
    "                shuffle=True,\n",
    "                validation_data=([t1_enc_val, t2_enc_val, i1_val, i2_val], label_val),\n",
    "                   callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joko-notebook",
   "language": "python",
   "name": "joko"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
